# Main Memory

* A program must be brought from disk into memory and placed within a process in order for it to run
* Main memory and registers are the only storage that the CPU can access directly
* Memory unit only sees a stream of:
  * Addresses and read requests, or
  * Address + data and write requests
* Register access is done in one clock cycle (or less, very fast)
* Main memory access can take many cycles, which can cause a **stall**
* Several **caches** sit between main memory and CPU registers
* Memory must be protected in order to ensure correct operation

#### Protection

* Must ensure that a process can only access the addresses in its address space
* We can provide two registers: a **base** and a **limit** register to define the range of addresses for a process (the logical address space)
* Hardware address protection
  * The CPU must check every memory access generated in user mode to be sure that the requested address(es) fall between the base and limit addresses
  * The instructions that load the base and limit registers are privileged

#### Address Binding

* Programs on disk that are ready to be brought into memory (to execute) form an input queue
  * Without any support, the programs must be loaded into address 0000
  * This is inconvenient
* Addresses are represented in different ways at different stages of a program's life
  * Source code address are usually **symbolic**
  * Compiled code addresses bind to relocatable addresses
    * e.g. 14 bytes from the beginning of this module
  * Linker or loader binds the relocatable addresses to absolute addresses
  * Each binding maps one address space to another
* Address binding of instructions and data to memory addresses can happen at three different stages
  * Compile-time
    * If memory location is known beforehand, the absolute code can be generated
    * The code must be recompiled if the starting location changes
  * Load-time
    * Must generate relocatable code if memory location is not known at compile time
  * Execution-time
    * Binding is delayed until runtime if the process can be moved during its execution from one memory segment to another
      * This requires hardware support for address maps, e.g. base and limit registers
* Logical vs. Physical address space
  * A logical address space is bound to a separate physical address space
    * **Logical address:** generated by the CPU in perspective of a program (also known as virtual address)
    * **Physical address:** address seen by the memory unit; a location that exists on the memory unit
  * In compile-time and bind-time addressing schemes, logical and physical addresses are the same
  * In execution-time addressing schemes, logical and physical addresses are different
  * The logical/physical address space is the set of all logical/physical addresses generated by a program

#### Memory Management Unit (MMU)

* A hardware device that maps logical addresses to physical ones at runtime (execution time)
  * Many methods available to do this
* A simple scheme is to simply add the value stored in the base register (i.e. the lowest address in the logical address space) to every virtual address
  * The base register is known as the **relocation register** in this case
  * For example, if the relocation register contained address `15000` and we had a logical address with a value of `47` it would map to the physical address `15047`
* User programs only deal with logical addresses; they never see the *real* physical addresses

#### Dynamic Loading

* The entirety of a program does not need to be in memory to execute
* In dynamic loading, a routine is not loaded until it is called
  * This gives better memory-space utilization; unused routines are never loaded
* All routines are kept on disk in relocatable load format
* This is especially useful when large amounts of code are needed to handle infrequently occurring cases
* No special support from OS is required
  * Implemented through program design
  * The OS can help by providing libraries to implement dynamic loading

#### Dynamic Linking

* **Static linking** combines system libraries and program code together into the binary executable
  * This is done by the loader
* **Dynamic linking** postpones linking until execution time
  * Also known as **shared libraries**
* Small pieces of code (stubs) are used to locate the appropriate library routine in memory
* A stub replaces itself with the address of the library routine and executes the routine
* The OS checks if the library routine is in a process's memory address
  * If not, it gets added to the address space
* Dynamic linking is especially useful for libraries

#### Contiguous Allocation

* The main memory must support both OS (kernel) and user processes 
* Memory is a limited resource, so it must be allocated efficiently
* Contiguous allocation is one early method for doing this
* Main memory can be split into two partitions
  * The first partition is for the resident OS, which is usually held in low memory with an interrupt vector
  * The second partition is for user processes, which are held in high memory
  * In this system, each process is contained in a single, contiguous section of memory
* Relocation registers are used to protect user processes from each other, and also to prevent them from changing OS code and data
  * The base register contains the value of the smallest physical address
  * The limit register contains the range of logical addressesâ€”each logical address must be less than the limit register
  * MMU maps logical address dynamically
  * This allows actions such as kernel code being **transient** and kernel changing size
    * Transience refers to something that is expected to be in memory for a short time only

#### Variable Partition

* Multiple partition allocation
  * The degree of multiprogramming is limited by the number of partitions
  * Partitions can be variable in size, and are sized according to a given process's needs
  * A **hole** is a block of available memory
    * Holes of various sizes are scattered throughout memory
  * When a process arrives, it is allocated memory from a hole large enough to accommodate it
  * When a process exists, it frees its partition 
  * The OS maintains information about allocated partitions and free partitions (holes)
* Dynamic storage allocation problem
  * How can we satisfy a request of size *n* from a list of free holes in memory?
    * **First fit:** allocate the first hole that is big enough
    * **Best fit:** allocate the smallest hole that is still big enough
      * Must search entire list unless it is ordered by size
      * Produces the smallest leftover hole
    * **Worst-fit:** allocate the largest hole
      * Also requires searching the entire list
      * Produces the largest leftover hole
    * First fit and best fit are better than worst fit in terms of speed and storage utilization
* Fragmentation
  * External fragmentation: the total memory space exists to satisfy a request, but it is not contiguous
  * Internal fragmentation: allocated memory may be slightly larger than requested memory
    * This size different is memory that is internal to a partition, but it is not being used
  * External fragmentation can be reduced by **compaction**
    * Shuffle memory contents to place all free memory together in one block
    * Compaction is only possible if relocation is dynamic and done at execution time

#### Paging

* The physical address space of a process can be non-contiguous, since a process is allocated physical memory whenever it's available
  * This avoids external fragmentation
  * Also avoids the problem of various sized memory chunks
* For paging, divide the physical memory into fixed-size blocks called **frames**
  * Frame size is a power of 2, between 512 bytes and 16 Megabytes
* Divide logical memory into blocks of same size called **pages**
  * Note that we still have internal fragmentation with this method!
* Keep track of all free frames
* To run a program of size *N* pages, we need to find *N* free frames and then load the program
* Set up a **page table** to translate logical addresses to physical addresses
* Address translation scheme
  * An address that is generated by the CPU is divided into:
    * **Page number:** used as an index into a page table which contains the base address of each page in physical memory 
    * **Page offset:** combined with base address to define the physical memory address that is sent to the memory unit
  * Given parameters $m$ and $n$, the logical address space size is $2^m$ and the page size is $2^n$
* Each entry in the page table points to the frame number in the physical address space (zero-indexed)
  * The index of the entry is the page number, so each entry maps page number to frame number

#### Implementation of Page Table

* The page table is kept in main memory
  * The **page table base register (PTBR)** points to the page table
  * The **page table length register (PTLR)** indicates the size of the page table
* In this setup, each data/instruction access requires two memory accesses (one for the page table and one for the data/instruction)

* The two-memory access problem can be solved by using a special fast-lookup hardware cache called **translation look-aside buffers (TLBs)** 

  * Also known as associative memory

* Translation look-aside buffer

  * The TLB is a memory cache that is used to reduce the time taken to access a user memory location
    * It is part of the MMU
    * Essentially an address translation cache; it stores recent translations of logical memory to physical memory
  * Some TLBs store address space identifiers (ASIDs) in each TLB entry; this uniquely identifies each process to provide address space protection for that process
    * Otherwise it would need to flush at every context switch
  * TLBs are typically small (64 to 1024 entries)
  * On a TLB miss, value is loaded into the TLB for faster access next time
    * Some entries can be wired down for permanent fast access

* Hardware

  * Associative memory search
    * Address translation for `(p, d)`, where `p` is the page number and `d` is the page offset
    * If `p` is in the associative register, then get the frame number from the TLB
    * Otherwise, get the frame number from the page table in memory as usual

* Effective access time

  * **Hit ratio** (or hit rate) is the percentage of times that a page number is found in the TLB

    * An 80% hit rate means that the desired page number is found in the TLB 80% of the time

  * Suppose that it takes 10 ns to access memory

    * If the page can be found in the TLB then we only need one memory access, so total access time is 10 ns
    * If not, we need to do two memory accesses so the total time is 20 ns

  * Effective access time: $EAT = (\text{hit rate})(m) + (1-\text{hit rate})(2m)$

    * $m$ is the memory access time

    * With the numbers above, the effective access time is:

      $EAT = (0.8)(10) + (0.2)(20) = 12 \text{ ns}$

#### Memory Protection

* Memory protection is implemented by associating a *protection bit* with each frame to indicate if it is read-only or if read-write access is allowed
  * Can also add more bits for more access options
* **Valid-invalid** bit is attached to each entry in the page table
  * `valid` indicates that the associated page in the process's logical address space (and is thus a legal page)
  * `invalid` indicates that the page is not in the process's logical address space
  * Can also use the page table length register (PTLR)
  * Any violations result in a trap being sent to the kernel

#### Shared Pages

* Shared code
  * One copy of read-only (reentrant) code is shared among processes
  * Similar to multiple threads sharing the same process space
  * Also useful for interprocess communication if sharing of read-write pages is allowed
* Private code and data
  * Each process keeps a separate copy of the code and data
  * The pages for the private code and data can appear anywhere in the logical address space

#### Structure of the Page Table

* Memoru structures for paging can get huge using straightforward methods
  * Consider a 32-bit logical address space and a page size of 4 KB ($2^{12}$ bytes)
  * The page table would have 1 million entries ($2^{32} / 2^{12}$)
  * If each page table entry is 4 bytes, then each process would have 4 MB of physical address space for the page table alone!
    * We don't want to allocate that continuously in main memory
  * One solution is to divide the page table into smaller units
* Hierarchical Page Tables
  * Break up the logical address space into multiple page tables
  * A simple technique is a two-level page table
  * We then page the page table
* Two-level paging example
  * A logical address (on a 32-bit machine with 1 KB ($2^{10}$ bytes) page size) is divided into:
    * A page number consisting of 22 bits
    * A page offset consisting of 10 bits
  * Since the page table is paged, the page number is further divided into:
    * A 10-bit page number
    * A 12-bit page offset
  * Then, a logical address consists of $p_1$ (10 bits), $p_2$ (10 bits) and $d$ (12 bits)
    * $p_1$ is an index into the outer page table, and $p_2$ is the displacement within the page of the inner page table
    * This is known as a **forward-mapped page table**
  * If a computer has 64-bit architecture, then this can be extended to three-level paging (though this may not be sufficient)
    * More levels reduce the amount of space taken up by each table but increase the number of memory accesses required to get actual data from memory
* Hashed Page Tables
  * This technique is commin is address spaces that are larger than 32 bits
  * The virtual page number is hashed into a page table
    * This page table contains a chain of elements hasing to the same location
  * Each element contains:
    * The virtual page number
    * The value of the mapped page frame
    * A pointer to the next element
  * Virtual page numbers are compared in this chain, searching for a match
    * If a match is found, the corresponding physical frame is extracted
  * A variation for 64-bit addresses is clustered page tables
    * Similar to hashed but each entry refers to several pages instead of just one
    * Especially useful for sparse address spaces
* Inverted Page Table
  * Rather than each process having a page table and keeping track of all possible logical pages, track all physical pages
  * One entry for each real page of memory
  * An entry consists of the logical address of the page stored in that real memory location, with information about the process that owns that page
  * Decreases memory needed to store each page table, but increases time needed to search the table when a page reference occurs
  * Use hash table to limit the search to one (or at most a few) page table entries
    * TLB can accelerate access times
  * How can shared memory be implemented?
    * One mapping of a logical address to the shared physical address

#### Swapping

* A process can be swapped temporarily out of memory to a backing store, and then brought back into memory to continue executing
  * This is necessary since the total physical space of a process can exceed physical memory size
* **Backing store:** a fast disk large enough to accomodate copies of all memory images for all users
  * Must provide direct access to these memory images
* **Roll out, roll in:** swapping variant used for priority-based scheduling algorithms
  * A lower-priority process is swapped out so a higher-priority process can be loaded and executed
* The major part of swap time is transfer time
  * Total transfer time is directly proprotional to the amount of memory swapped
* Does the swapped-out process need to swap back in to the same physical addresses?
  * Depends on the address binding method
* Modified versions of swapping are found on many systems
  * Swapping is normally disabled
  * Swapping is started if more than the threshold amount of memory is allocated
  * Swapping is disabled again once memory demand is reduced below the threshold

#### Context Switch Time Including Swapping

* If the next process to be put on CPU is not in memory, then we need to swap out a process and swap in the target process
  * The context switch time can be very high in this case
* Example: 100 MB process swapping with transfer rate of 50 MB/sec
  * Swap out time is 2000 ms
  * Swap in time is also 2000 ms
  * Total context switch swapping component time is 4000 ms
* It is possible to reduce the size of the memory being swapping if we know how much memory is actually being used
* Other constraints on swapping
  * Pending I/O: can't swap out as I/O would occur to the wrong process
    * Workaround: always transfer I/O to kernel space, then to I/O device (known as double buffering, which adds additional overhead)
* Standard swapping is not used in modern operating systems, but the modified version is common (i.e. with swapping alternating between being enabled/disabled)
  * Main idea: swap only when free memory is extremely low